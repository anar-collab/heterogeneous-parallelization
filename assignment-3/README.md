1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

В CUDA используются несколько типов памяти: регистры, разделяемая память, глобальная память, а также константная и текстурная память.
Самыми быстрыми являются регистры, затем идёт разделяемая память, которая доступна всем потокам внутри одного блока. Глобальная память самая медленная, но имеет большой объём и доступна всем потокам. Константная и текстурная память оптимизированы под специфические шаблоны доступа.

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Разделяемая память эффективна, когда потоки одного блока многократно используют одни и те же данные. Перемещение данных из глобальной памяти в разделяемую снижает количество медленных обращений к глобальной памяти и ускоряет выполнение вычислений.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

Производительность сильно зависит от того, коалесцирован ли доступ. Если соседние потоки обращаются к соседним адресам памяти, GPU может объединить эти обращения, что ускоряет выполнение. Некоалесцированный доступ приводит к большему числу операций чтения и снижает производительность.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Даже при одинаковых вычислениях разное расположение данных в памяти и разные шаблоны доступа могут приводить к различному количеству обращений к памяти, конфликтам в разделяемой памяти и задержкам. В результате один и тот же алгоритм может работать быстрее или медленнее в зависимости от способа работы с памятью.

5. Как размер блока потоков влияет на производительность CUDA-ядра?

Размер блока влияет на количество одновременно выполняемых потоков и использование ресурсов GPU. Слишком маленькие блоки не полностью загружают устройство, а слишком большие могут привести к нехватке регистров или разделяемой памяти. Оптимальный размер блока помогает достичь высокой загрузки вычислительных ядер.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

Варп — это группа из 32 потоков, которые выполняются одновременно. Если внутри варпа происходит ветвление и потоки идут по разным путям, выполнение становится последовательным, что снижает производительность. Поэтому важно минимизировать дивергенцию внутри варпа.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

При выборе конфигурации нужно учитывать:

размер обрабатываемых данных;

количество доступных ресурсов GPU;

объём используемой разделяемой памяти и регистров;

характер доступа к памяти.

Правильная конфигурация позволяет максимально эффективно использовать аппаратные ресурсы.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

Во многих CUDA-программах узким местом является доступ к памяти, а не сами вычисления. Оптимизация памяти (коалесцированный доступ, использование разделяемой памяти) часто даёт больший выигрыш, чем изменение алгоритма, поэтому анализ памяти является первым шагом оптимизации.
